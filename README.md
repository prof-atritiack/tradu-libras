<p align="center">
  <img src="https://img.shields.io/badge/python-3.10-blue?logo=python" />
  <img src="https://img.shields.io/badge/mediapipe-informational?logo=google" />
  <img src="https://img.shields.io/badge/opencv-4.x-green?logo=opencv" />
  <img src="https://img.shields.io/badge/scikit--learn-ML-orange?logo=scikit-learn" />
   <img src="https://img.shields.io/badge/status-em%20desenvolvimento-lightgrey" />
</p>

# TraduLibras

Sistema de reconhecimento de LÃ­ngua Brasileira de Sinais (LIBRAS) usando visÃ£o computacional.

## ðŸ“‹ PrÃ©-requisitos

- Python 3.10 ou superior
- Webcam funcionando
- Sistema operacional: Windows, Linux ou macOS
- ConexÃ£o com a internet (para a primeira instalaÃ§Ã£o)

## ðŸš€ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/prof-atritiack/libras-js.git
cd libras-js
```

2. Crie um ambiente virtual Python:
```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# Linux/macOS
python3 -m venv .venv
source .venv/bin/activate
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

## ðŸ’» Executando o projeto

1. Ative o ambiente virtual (se ainda nÃ£o estiver ativo):
```bash
# Windows
.venv\Scripts\activate

# Linux/macOS
source .venv/bin/activate
```

2. Execute a aplicaÃ§Ã£o:
```bash
python app.py
```

3. Abra seu navegador e acesse:
```
http://localhost:5000
```

## ðŸ“± Usando o TraduLibras

1. Na pÃ¡gina inicial, clique em "ComeÃ§ar Agora" ou acesse a seÃ§Ã£o "CÃ¢mera"
2. Permita o acesso Ã  sua webcam quando solicitado
3. Posicione sua mÃ£o no centro da cÃ¢mera
4. FaÃ§a os sinais das letras em LIBRAS
5. O sistema reconhecerÃ¡ as letras e formarÃ¡ palavras
6. Use o botÃ£o "Falar" para ouvir o texto reconhecido
7. Use "Limpar" para recomeÃ§ar

## ðŸ” Funcionalidades

- Reconhecimento em tempo real de letras em LIBRAS
- Interface web moderna e responsiva
- ConversÃ£o de texto para fala
- Tutorial interativo
- Feedback visual em tempo real

## ðŸ› ï¸ Tecnologias Utilizadas

- Flask (Framework web)
- OpenCV (Processamento de imagem)
- MediaPipe (DetecÃ§Ã£o de mÃ£os)
- Scikit-learn (Modelo de machine learning)
- gTTS (ConversÃ£o de texto para fala)
- HTML/CSS (Interface do usuÃ¡rio)

## âš ï¸ Requisitos do Sistema

### Requisitos MÃ­nimos:
- Processador: Dual Core 2GHz
- MemÃ³ria RAM: 4GB
- Webcam: 720p
- EspaÃ§o em disco: 500MB

### Requisitos Recomendados:
- Processador: Quad Core 2.5GHz
- MemÃ³ria RAM: 8GB
- Webcam: 1080p
- EspaÃ§o em disco: 1GB

## ðŸ”§ SoluÃ§Ã£o de Problemas

### A webcam nÃ£o inicia:
1. Verifique se sua webcam estÃ¡ conectada
2. Certifique-se de que nenhum outro programa estÃ¡ usando a cÃ¢mera
3. Recarregue a pÃ¡gina
4. Reinicie a aplicaÃ§Ã£o

### Reconhecimento impreciso:
1. Verifique a iluminaÃ§Ã£o do ambiente
2. Mantenha sua mÃ£o a aproximadamente 50cm da cÃ¢mera
3. Evite movimentos bruscos
4. Certifique-se de que nÃ£o hÃ¡ objetos ou pessoas no fundo

### Erro ao instalar dependÃªncias:
1. Verifique sua conexÃ£o com a internet
2. Atualize o pip: `python -m pip install --upgrade pip`
3. Tente instalar as dependÃªncias uma a uma

## ðŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## âœ¨ Contribuindo

1. FaÃ§a um Fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ðŸ‘¥ Equipe

Desenvolvido com â¤ï¸ pela equipe TraduLibras

## Tradutor de Libras com IA usando MediaPipe + Scikit-learn

Um projeto educacional que integra **visÃ£o computacional**, **machine learning** e **sÃ­ntese de voz** para traduzir gestos da LÃ­ngua Brasileira de Sinais (Libras) em letras, palavras e frases. Ideal para demonstraÃ§Ãµes de acessibilidade, inclusÃ£o digital e ensino tÃ©cnico.

---

## ðŸš€ Funcionalidades jÃ¡ implementadas

âœ… Coleta de gestos com webcam e rotulagem manual  
âœ… DetecÃ§Ã£o de mÃ£os com **MediaPipe**  
âœ… NormalizaÃ§Ã£o dos dados baseada no punho  
âœ… Treinamento de modelo com **Random Forest** (scikit-learn)  
âœ… Reconhecimento em tempo real de letras com estabilizaÃ§Ã£o  
âœ… Estrutura inicial para acÃºmulo de letras â†’ palavras

---

## 2ï¸âƒ£ Como rodar o projeto

### â–¶ï¸ Etapa 1 â€“ Coletar os dados dos gestos

```bash
python coletar_gestos.py
```

- A cÃ¢mera serÃ¡ ativada.
- Posicione a mÃ£o com o gesto correspondente Ã  letra desejada.
- Pressione a tecla da letra (`A`, `B`, etc.).
- O dado serÃ¡ salvo automaticamente em `gestos_libras.csv`.

ðŸ“Œ Recomendado: coletar entre **30 a 50 amostras por letra** com variaÃ§Ã£o de posiÃ§Ã£o e Ã¢ngulo.

---

### ðŸ§  Etapa 2 â€“ Treinar o modelo

```bash
python treinar_modelo.py
```

- Aplica balanceamento entre as letras.
- Treina um modelo com scikit-learn.
- Salva como `modelo_libras.pkl`.

---

### ðŸ”´ Etapa 3 â€“ Reconhecimento em tempo real

```bash
python reconhecer_em_tempo_real.py
```

- Reconhece a mÃ£o com MediaPipe.
- Identifica e exibe a letra.
- Usa verificaÃ§Ã£o de estabilidade para reduzir ruÃ­do.

---

## ðŸ“ Estrutura do projeto

```bash
tradutor-libras/
â”œâ”€â”€ coletar_gestos.py              # Coleta e rotulagem dos gestos
â”œâ”€â”€ treinar_modelo.py              # Treinamento do modelo de IA
â”œâ”€â”€ reconhecer_em_tempo_real.py    # Reconhecimento com webcam
â”œâ”€â”€ modelo_libras.pkl              # Modelo treinado (Random Forest)
â”œâ”€â”€ gestos_libras.csv              # Dataset dos gestos (normalizado)
â”œâ”€â”€ requirements.txt               # [pendente] Lista de dependÃªncias
â”œâ”€â”€ streamlit_app.py               # [pendente] Interface web
â”œâ”€â”€ audio_output.py                # [pendente] GeraÃ§Ã£o de Ã¡udio com gTTS
â”œâ”€â”€ frase_mapping.py               # [pendente] Mapeamento de palavras para frases
â””â”€â”€ README.md                      # DocumentaÃ§Ã£o do projeto
```

---

## ðŸ§± Arquitetura do Projeto

```mermaid
graph LR
    CAM[Webcam + MediaPipe] --> COLETA[Coleta de Dados]
    COLETA --> CSV[Arquivo CSV]
    CSV --> TREINAMENTO[Modelo Random Forest]
    TREINAMENTO --> PKL[modelo_libras.pkl]
    PKL --> RECOGNITION[Reconhecimento em tempo real]
    RECOGNITION --> LETRA[Letra reconhecida]
    LETRA --> PALAVRA[FormaÃ§Ã£o de palavra]
    PALAVRA --> FRASE[Frase mapeada]
    FRASE --> AUDIO[gTTS: voz]


